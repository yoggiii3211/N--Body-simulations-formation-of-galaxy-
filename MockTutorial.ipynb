{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c69f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sysp\n",
    "import scipy.spatial as syspat\n",
    "import sys\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e9c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#///////////////////////////////////////////////////////////////////\n",
    "# HOD Fits\n",
    "#///////////////////////////////////////////////////////////////////\n",
    "class HODFits(object):\n",
    "    \"\"\" Fitting functions and derivatives specifying best fit 5-parameter HOD fits \n",
    "         from Paul, Pahwa, Paranjape 2019, Table 3.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Best fit HOD parameters and derivatives as function of luminosity threshold Mr. \"\"\"\n",
    "\n",
    "        # dictionary for best fit values of a0,a1,a2 for 5 HOD params\n",
    "        # lgMmin,siglgM,lgM1,lgM0,alpha\n",
    "        # fits are of the form a0 + a1*x + a2*x**2 for all except siglgM\n",
    "        # in which case fit is a0 + a1*erf(x/a2)\n",
    "\n",
    "        self.bf = {'lgMmin':np.array([12.33,-0.85,0.19]),\n",
    "                   'siglgM':np.array([0.44,-0.16,0.3]),\n",
    "                   'lgM1':np.array([13.52,-0.72,0.16]),\n",
    "                   'lgM0':np.array([12.24,-0.54,0.0]),\n",
    "                   'alpha':np.array([1.16,-0.20,0.10])}\n",
    "\n",
    "    def hod_fit(self,param,Mr):\n",
    "        \"\"\" Return HOD parameter param (string) at luminosity threshold Mr.\n",
    "             param can be one of 'lgMmin','siglgM','lgM1','lgM0','alpha'.\n",
    "        \"\"\"\n",
    "        a0,a1,a2 = self.bf[param]\n",
    "        x = Mr + 20.5\n",
    "        out = (a0 + a1*x + a2*x**2\n",
    "               if param != 'siglgM' else\n",
    "               a0 + a1*sysp.erf(x/a2))\n",
    "        return out\n",
    "\n",
    "    def hod_fit_deriv(self,param,Mr):\n",
    "        \"\"\" Return derivative wrt Mr for HOD parameter param (string) at luminosity threshold Mr.\n",
    "             param can be one of 'lgMmin','siglgM','lgM1','lgM0','alpha'.\n",
    "        \"\"\"\n",
    "        a0,a1,a2 = self.bf[param]\n",
    "        x = Mr + 20.5\n",
    "        out = (a1 + 2*a2*x\n",
    "               if param != 'siglgM' else\n",
    "               (a1/a2)*2/np.sqrt(np.pi)*np.exp(-(x/a2)**2))\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "#///////////////////////////////////////////////////////////////////\n",
    "# HOD Functions\n",
    "#///////////////////////////////////////////////////////////////////\n",
    "class HODFunctions(HODFits):\n",
    "    \"\"\" Functions and derivatives specifying 5-parameter HODs \n",
    "         Uses fits from Paul, Pahwa, Paranjape 2019.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" HOD functions and derivatives as function of luminosity threshold Mr. \"\"\"\n",
    "\n",
    "        HODFits.__init__(self)\n",
    "\n",
    "    def erf_arg(self,Mr,lgm):\n",
    "        \"\"\" Convenience function.\n",
    "             If both arguments are arrays, output has shape (lgm.size,Mr.size).\n",
    "        \"\"\"\n",
    "        Mr_sc = np.isscalar(Mr)\n",
    "        lgm_sc = np.isscalar(lgm)\n",
    "\n",
    "        lgm_arr = np.outer(lgm,np.ones(Mr.size)) if ((not Mr_sc) & (not lgm_sc)) else 1.0*lgm\n",
    "        erfarg = (lgm_arr - self.hod_fit('lgMmin',Mr))/self.hod_fit('siglgM',Mr)\n",
    "        return erfarg\n",
    "\n",
    "    def fcen_thresh(self,Mr,lgm):\n",
    "        \"\"\" fcen(>L|m) = (1/2)[1 + erf(log10(m/Mmin)/siglgM)]. \n",
    "             If both arguments are arrays, output has shape (lgm.size,Mr.size).\n",
    "        \"\"\"\n",
    "        erfarg = self.erf_arg(Mr,lgm)\n",
    "        out = 0.5*(1+sysp.erf(erfarg))\n",
    "        return out\n",
    "\n",
    "    def Nsat_thresh(self,Mr,lgm):\n",
    "        \"\"\" Nsat(>L|m) = ((m - M0)/M1)^alpha.\n",
    "             If both arguments are arrays, output has shape (lgm.size,Mr.size).\n",
    "        \"\"\"\n",
    "        M0 = 10**self.hod_fit('lgM0',Mr)\n",
    "        M1 = 10**self.hod_fit('lgM1',Mr)\n",
    "        alpha = self.hod_fit('alpha',Mr)\n",
    "        mhalo = 10**lgm\n",
    "\n",
    "        Mr_sc = np.isscalar(Mr)\n",
    "        lgm_sc = np.isscalar(lgm)\n",
    "\n",
    "        if Mr_sc & lgm_sc:\n",
    "            out = ((mhalo - M0)/M1)**alpha if mhalo > M0 else 0.0\n",
    "        else:\n",
    "            mhalo_arr = np.outer(mhalo,np.ones(Mr.size)) if ((not Mr_sc) & (not lgm_sc)) else 1.0*mhalo\n",
    "            Dm = (mhalo_arr - M0)/M1\n",
    "            Dm[Dm < 0.0] = 0.0\n",
    "            out = Dm**alpha\n",
    "\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1c5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mocker(HODFunctions):\n",
    "    def __init__(self):\n",
    "        \n",
    "        HODFunctions.__init__(self)\n",
    "        self.halo_cat = 'D:/out_1.parents'\n",
    "        self.redshift = 0.0\n",
    "        self.Om = 0.276\n",
    "        self.Lbox = 300.0 # Mpc/h\n",
    "        self.massdef = 'm200b'\n",
    "        self.mmin = 2e11 # Msun/h\n",
    "        self.Mrmax = -20.5           #sectorfx\n",
    "        self.Dvir = 200*self.Om\n",
    "        \n",
    "        self.rhoc = 2.7754e11 # (Msun/h) / (Mpc/h)^3\n",
    "        self.rhoc_z = self.rhoc*self.EHub(self.redshift)**2\n",
    "        \n",
    "        self.rng = np.random.RandomState(seed=42)\n",
    "\n",
    "        dMr = 0.001\n",
    "        nMr = int((23.5+self.Mrmax)/dMr)\n",
    "        self.Mrvals = np.linspace(-23.5,self.Mrmax,nMr) # useful for interpolation later\n",
    "        self.dMr = self.Mrvals[1]-self.Mrvals[0]\n",
    "        \n",
    "        self.halodatatype = {'ID':int,'descID':int,\n",
    "                            'mbnd_vir':float,'vmax':float,'vrms':float,'rvir':float,'rs':float,'np':int,\n",
    "                            'x':float,'y':float,'z':float,'vx':float,'vy':float,'vz':float,\n",
    "                            'Jx':float,'Jy':float,'Jz':float,'spin':float,'rs_klypin':float,\n",
    "                            'mvir':float,'m200b':float,'m200c':float,'mCustom2':float,'mCustom':float,\n",
    "                            'Xoff':float,'Voff':float,'spin_bullock':float,'b_to_a':float,'c_to_a':float,\n",
    "                            'Ax':float,'Ay':float,'Az':float,'b_to_a_500c':float,'c_to_a_500c':float,\n",
    "                            'Ax_500c':float,'Ay_500c':float,'Az_500c':float,\n",
    "                            'TbyU':float,'Mpe_Behroozi':float,'Mpe_Diemer':float,'halfmassradius':float,\n",
    "                            'pid':int} \n",
    "\n",
    "        \n",
    "        self.halodatanames = ['ID','descID',\n",
    "                              'mbnd_vir','vmax','vrms','rvir','rs','np',\n",
    "                              'x','y','z','vx','vy','vz','Jx','Jy','Jz','spin','rs_klypin',\n",
    "                              'mvir','m200b','m200c','mCustom2','mCustom',\n",
    "                              'Xoff','Voff','spin_bullock','b_to_a','c_to_a',\n",
    "                              'Ax','Ay','Az','b_to_a_500c','c_to_a_500c',\n",
    "                              'Ax_500c','Ay_500c','Az_500c',\n",
    "                              'TbyU','Mpe_Behroozi','Mpe_Diemer','halfmassradius',\n",
    "                              'pid']\n",
    "        \n",
    "    ############################################################\n",
    "    def EHub(self,z):\n",
    "        return np.sqrt(self.Om*(1+z)**3 + 1-self.Om)\n",
    "    ############################################################\n",
    "    \n",
    "    ############################################################\n",
    "    def read_this(self):\n",
    "        halos = pd.read_csv(self.halo_cat,dtype=self.halodatatype,names=self.halodatatype.keys(),#self.halodatanames,\n",
    "                            comment='#',delim_whitespace=True,header=None).to_records()\n",
    "        return halos\n",
    "    ############################################################\n",
    "    \n",
    "\n",
    "    ############################################################\n",
    "    def prep_halo_data(self):\n",
    "        \"\"\" Reads and cleans catalog by selecting parent objects with mass at least mmin.\n",
    "            Returns structured array for full halo properties.\n",
    "        \"\"\" \n",
    "        halos = self.read_this()\n",
    "        Nhalos_all = halos.size\n",
    "        cond_clean = (halos[self.massdef] >= self.mmin)\n",
    "        cond_clean = cond_clean & (halos['pid'] == -1)\n",
    "\n",
    "        halos = halos[cond_clean]\n",
    "        print(\"Kept {0:d} of {1:d} objects in catalog\".format(halos.size,Nhalos_all))\n",
    "\n",
    "        del cond_clean\n",
    "        gc.collect()\n",
    "\n",
    "        return halos\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ############################################################\n",
    "    def occupy_halos(self,halo_mass):\n",
    "        \"\"\" Decide which halos are occupied. \n",
    "             Input is 1-d array of halo masses. Output is 1-d boolean array of same size.\n",
    "        \"\"\"\n",
    "        print(\"Occupying halos... \")\n",
    "\n",
    "        occupy = np.ones(halo_mass.size,dtype=bool)\n",
    "        fcen_min = self.fcen_thresh(self.Mrmax,np.log10(halo_mass))\n",
    "        u = self.rng.rand(halo_mass.size)\n",
    "        occupy[u > fcen_min] = False\n",
    "\n",
    "        print_string = \"... {0:d} of {1:d} halos occupied\\n\".format(np.where(occupy)[0].size,occupy.size)\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "        return occupy\n",
    "    ############################################################\n",
    "    \n",
    "\n",
    "    ############################################################\n",
    "    def assign_centrals(self,halos):\n",
    "        \"\"\" Allocate memory and assign (some) central properties. \"\"\"\n",
    "\n",
    "        print(\"Assigning values for centrals... \")\n",
    "        ####################################################\n",
    "        # Allocate memory for centrals\n",
    "        centrals = np.zeros(halos.size,dtype=[('haloid','int'),\n",
    "                                              ('lgm','double'),('rvir','double'),('con','double'),\n",
    "                                              ('x','double'),('y','double'),('z','double'),\n",
    "                                              ('Mr','double'),('Nsat','int')])\n",
    "\n",
    "        print(\"... halo IDs, halo masses, positions\")\n",
    "        centrals['haloid'] = halos['ID']\n",
    "        centrals['lgm'] = np.log10(halos[self.massdef])\n",
    "        centrals['x'] = halos['x']\n",
    "        centrals['y'] = halos['y']\n",
    "        centrals['z'] = halos['z']\n",
    "        \n",
    "        rvir = (3*halos[self.massdef]/(4*np.pi*self.Dvir*self.rhoc_z))**(1/3.)\n",
    "        # Units Mpc/h [physical]\n",
    "        centrals['rvir'] = rvir*(1+self.redshift) # store comoving value\n",
    "        centrals['con'] = rvir/(halos['rs']*1e-3/(1+self.redshift)) # rs is comoving kpc/h\n",
    "        \n",
    "        ####################################################\n",
    "        # Assign central luminosity\n",
    "        centrals['Mr'] = self.assign_central_luminosity(centrals['lgm'])\n",
    "\n",
    "        ####################################################\n",
    "        # Poisson numbers for Nsat\n",
    "        centrals['Nsat'] = self.get_Poisson(centrals['lgm'])\n",
    "\n",
    "        print_string = '... done\\n'\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "        return centrals\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ############################################################\n",
    "    def get_Poisson(self,lgm_halos):\n",
    "        \"\"\" Calculate mean Nsat and generate Poisson numbers of satellites. \n",
    "            Can be generalised to depend on more than halo mass.\n",
    "        \"\"\"\n",
    "        print(\"... Poisson satellite counts\")\n",
    "        mean_Nsat = self.Nsat_thresh(self.Mrmax,lgm_halos)\n",
    "        Nsat_values = self.rng.poisson(mean_Nsat)\n",
    "\n",
    "        return Nsat_values\n",
    "    ############################################################\n",
    "    \n",
    "\n",
    "    ############################################################\n",
    "    def assign_central_luminosity(self,lgm_halos):\n",
    "        \"\"\" Assign central luminosities. Can be generalised to depend on more than halo mass. \"\"\"\n",
    "        \n",
    "        print(\"... luminosities\")\n",
    "        Mr_cen = np.zeros(lgm_halos.size,dtype=float)\n",
    "\n",
    "        ############################################\n",
    "        # Generate uniform deviates\n",
    "        u = self.rng.rand(lgm_halos.size)\n",
    "\n",
    "        ################################################\n",
    "        for h in range(lgm_halos.size):\n",
    "            # Luminosity function is Pcen(>L|m) = fcen(>L|m)/fcen(>Lmin|m)\n",
    "            PcenL = self.fcen_thresh(self.Mrvals,lgm_halos[h])/self.fcen_thresh(self.Mrmax,lgm_halos[h])\n",
    "            # keeping this in loop is not much slower than vectorised calc, but more memory-efficient\n",
    "\n",
    "            # Find largest L (smallest Mr) where Pcen(>L|m) > u\n",
    "            Mr_upp = self.Mrvals[PcenL > u[h]][0]\n",
    "\n",
    "            # Find smallest L (largest Mr) where Pcen(>L|m) <= u\n",
    "            Mr_low = self.Mrvals[PcenL <= u[h]][-1]\n",
    "            # choose fainter of the two (enforce nesting of HOD)\n",
    "            Mr_cen[h] = np.max([Mr_upp,Mr_low])\n",
    "        ################################################\n",
    "        \n",
    "        del u\n",
    "        gc.collect()\n",
    "\n",
    "        return Mr_cen\n",
    "    ############################################################\n",
    "\n",
    "    \n",
    "\n",
    "    ########################################################\n",
    "    def assign_satellites(self,centrals):\n",
    "        \"\"\" Allocate memory and assign (some) satellite values.\"\"\"\n",
    "        print(\"Assigning values for satellites... \")\n",
    "\n",
    "        Nsat_tot = np.sum(centrals['Nsat'])\n",
    "\n",
    "        ####################################################\n",
    "        # Allocate memory for satellites\n",
    "        satellites = np.zeros(Nsat_tot,dtype=[('haloid','int'),\n",
    "                                              ('lgm','double'),('con','double'),\n",
    "                                              ('x','double'),('y','double'),('z','double'),\n",
    "                                              ('Mr','double')])\n",
    "\n",
    "        print(\"... halo properties\")\n",
    "        s_lo = 0\n",
    "        for h in range(centrals.size):\n",
    "            s_hi = s_lo + centrals['Nsat'][h]\n",
    "            ################################################\n",
    "            if centrals['Nsat'][h]:\n",
    "                sl = np.s_[s_lo:s_hi]\n",
    "                ############################################\n",
    "                satellites['haloid'][sl] = centrals['haloid'][h]\n",
    "                satellites['lgm'][sl] = centrals['lgm'][h]\n",
    "                satellites['con'][sl] = centrals['con'][h]\n",
    "            ################################################\n",
    "            # Update\n",
    "            s_lo = s_hi\n",
    "\n",
    "        print(\"... positions\")\n",
    "        s_lo = 0\n",
    "        for h in range(centrals.size):\n",
    "            s_hi = s_lo + centrals['Nsat'][h]\n",
    "            ################################################\n",
    "            if centrals['Nsat'][h]:\n",
    "                sl = np.s_[s_lo:s_hi]\n",
    "                ############################################\n",
    "                sx,sy,sz = self.assign_satellite_pos(centrals,h)\n",
    "                satellites['x'][sl] = sx\n",
    "                satellites['y'][sl] = sy\n",
    "                satellites['z'][sl] = sz\n",
    "            ################################################\n",
    "            # Update\n",
    "            s_lo = s_hi\n",
    "\n",
    "        print(\"... luminosities\")\n",
    "        s_lo = 0\n",
    "        for h in range(centrals.size):\n",
    "            s_hi = s_lo + centrals['Nsat'][h]\n",
    "            ################################################\n",
    "            if centrals['Nsat'][h]:\n",
    "                ############################################\n",
    "                sMr = self.assign_satellite_luminosities(centrals,h)\n",
    "                satellites['Mr'][s_lo:s_hi] = sMr\n",
    "            ################################################\n",
    "            # Update\n",
    "            s_lo = s_hi\n",
    "\n",
    "        gc.collect\n",
    "\n",
    "        print_string = '... done\\n'\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "        return satellites\n",
    "    ########################################################\n",
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    def assign_satellite_luminosities(self,centrals,h):\n",
    "        \"\"\" Assign satellite luminosities. \"\"\"\n",
    "\n",
    "        Nsat_h = centrals['Nsat'][h]\n",
    "        Mr_cen = centrals['Mr'][h]\n",
    "        lgmhalo = centrals['lgm'][h]\n",
    "        PsatL = self.Nsat_thresh(self.Mrvals,lgmhalo)/self.Nsat_thresh(self.Mrmax,lgmhalo)\n",
    "\n",
    "        ####################################################\n",
    "        # Generate luminosities, without worrying about Lcen.\n",
    "        # ... generate Nsat_h uniform deviates\n",
    "        u = self.rng.rand(Nsat_h)\n",
    "        # ... find largest L (smallest Mr) where Psat(>L|m) > u\n",
    "        Mr_sat = np.array([self.Mrvals[(PsatL >= u[s])][0] for s in range(Nsat_h)])\n",
    "\n",
    "        return Mr_sat\n",
    "    ########################################################\n",
    "    \n",
    "\n",
    "    ########################################################\n",
    "    def assign_satellite_pos(self,centrals,h):\n",
    "        \"\"\" Assign satellite positions and velocities acc to NFW profile using halo concentration. \"\"\"\n",
    "        # Number of satellites in this halo\n",
    "        Nsat_h = centrals['Nsat'][h]\n",
    "        # Virial radius [comoving Mpc/h]\n",
    "        rvir = centrals['rvir'][h]\n",
    "        con = centrals['con'][h]\n",
    "\n",
    "        sat_pos = self.gen_NFW_profile(Nsat_h,cvir=con,Rvir=rvir,rng=self.rng)\n",
    "        sx = sat_pos[:,0] + centrals['x'][h]\n",
    "        sy = sat_pos[:,1] + centrals['y'][h]\n",
    "        sz = sat_pos[:,2] + centrals['z'][h]\n",
    "\n",
    "        sx = sx % self.Lbox\n",
    "        sy = sy % self.Lbox\n",
    "        sz = sz % self.Lbox\n",
    "\n",
    "        return sx,sy,sz\n",
    "    \n",
    "    \n",
    "    ############################################################\n",
    "    def gen_NFW_profile(self,Nsat,cvir=None,Rvir=None,rng=None,include_cen=False,clean_up=False):\n",
    "        \"\"\" Generate 3-d points distributed according to specified radial profile.\n",
    "            Returns array of shape (Ngal,3) where Ngal = Nsat if include_cen = False else Nsat+1\n",
    "            and central is assumed to be at origin. (Can include spatial offset later.)\n",
    "        \"\"\"\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState(42)\n",
    "        phi = 2*np.pi*rng.rand(Nsat)\n",
    "        cos_theta = 2*rng.rand(Nsat) - 1\n",
    "        sin_theta = np.sqrt(1-cos_theta**2)\n",
    "        \n",
    "        rsamp = self.gen_rsamp(Nsat,cvir=cvir,Rvir=Rvir,rng=rng,clean_up=clean_up)\n",
    "\n",
    "        x_trc = rsamp*sin_theta*np.sin(phi)\n",
    "        y_trc = rsamp*sin_theta*np.cos(phi)\n",
    "        z_trc = rsamp*cos_theta\n",
    "\n",
    "        sample = np.array([x_trc,y_trc,z_trc]).T\n",
    "        if include_cen:\n",
    "            sample = np.append(sample,[[0.,0.,0.]],axis=0)\n",
    "            \n",
    "        if clean_up:\n",
    "            del x_trc,y_trc,z_trc\n",
    "            gc.collect()\n",
    "\n",
    "        return sample\n",
    "    ############################################################\n",
    "    \n",
    "    \n",
    "    ############################################################\n",
    "    def gen_rsamp(self,Nsat,cvir=None,Rvir=None,rng=None,clean_up=False):\n",
    "        \"\"\" Generate radial location sample for speficied profile. \n",
    "            Return array of r values of shape (Nsat,).\n",
    "        \"\"\"\n",
    "        xmax = 2*cvir\n",
    "\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState(42)\n",
    "\n",
    "        xfine = np.linspace(0,xmax,100000)\n",
    "        dx = xfine[1]-xfine[0]\n",
    "        Px = np.zeros_like(xfine)\n",
    "        \n",
    "        rs = Rvir/cvir\n",
    "        Px = self.Mencl_nfw(xfine)\n",
    "        ind_small = np.where(xfine < 1e-3)[0]\n",
    "        if ind_small.size:\n",
    "            Px[ind_small] = xfine[ind_small]**2/2 - 2*xfine[ind_small]**3/3.0 \n",
    "            Px[ind_small] = Px[ind_small] + 3*xfine[ind_small]**4/4.0 - 4*xfine[ind_small]**5/5.0\n",
    "        Px /= self.Mencl_nfw(cvir)\n",
    "                \n",
    "        vran = rng.rand(Nsat)\n",
    "        rsamp = np.interp(vran,Px,xfine)\n",
    "        if np.any(rsamp <= dx):\n",
    "            print('! Warning ! : Ignore separations x < {0:.2e}'.format(dx))\n",
    "\n",
    "        if clean_up:\n",
    "            del xfine,Px\n",
    "            gc.collect()\n",
    "        \n",
    "        rsamp *= rs\n",
    "        \n",
    "        return rsamp\n",
    "    ############################################################\n",
    "    \n",
    "    \n",
    "    ############################################################\n",
    "    def Mencl_nfw(self,x):\n",
    "        \"\"\" Convenience function for NFW enclosed mass. Expect x = r/rs. \"\"\"\n",
    "        return np.log(1+x) - x/(1+x)\n",
    "    ############################################################\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################\n",
    "    def mock_it(self):\n",
    "        \"\"\" Main execution routine. \"\"\"        \n",
    "        # halo data\n",
    "        halos_all = self.prep_halo_data()\n",
    "\n",
    "        # occupy halos\n",
    "        occupy = self.occupy_halos(halos_all[self.massdef])\n",
    "        halos = halos_all[occupy]\n",
    "        all_masses = halos_all[self.massdef]\n",
    "        del halos_all\n",
    "        gc.collect()\n",
    "\n",
    "        # galaxy properties except color and derived props\n",
    "        centrals = self.assign_centrals(halos)\n",
    "        satellites = self.assign_satellites(centrals)\n",
    "        del halos\n",
    "        gc.collect()\n",
    "\n",
    "        print_string = \"... {0:d} galaxies created\\n\".format(centrals.size + satellites.size)\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "        print_string = '... all done\\n'\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "        return centrals,satellites,all_masses\n",
    "\n",
    "    ############################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0a0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = Mocker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1601583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# halos = mm.prep_halo_data()\n",
    "# occupy = mm.occupy_halos(halos[mm.massdef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383ec582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.yscale('log')\n",
    "# plt.hist(np.log10(halos['m200b']),bins=100,label='all')\n",
    "# plt.hist(np.log10(halos['m200b'][occupy]),bins=100,label='occupied')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcd25b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:/out_1.parents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16776\\98655966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcentrals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msatellites\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_masses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmock_it\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16776\\565297720.py\u001b[0m in \u001b[0;36mmock_it\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;34m\"\"\" Main execution routine. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;31m# halo data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[0mhalos_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprep_halo_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# occupy halos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16776\\565297720.py\u001b[0m in \u001b[0;36mprep_halo_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mstructured\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mhalo\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \"\"\" \n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mhalos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_this\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mNhalos_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhalos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mcond_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhalos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmassdef\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16776\\565297720.py\u001b[0m in \u001b[0;36mread_this\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_this\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         halos = pd.read_csv(self.halo_cat,dtype=self.halodatatype,names=self.halodatatype.keys(),#self.halodatanames,\n\u001b[0m\u001b[0;32m     54\u001b[0m                             comment='#',delim_whitespace=True,header=None).to_records()\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhalos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:/out_1.parents'"
     ]
    }
   ],
   "source": [
    "centrals,satellites,all_masses = mm.mock_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211995dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.xlim(mm.Mrmax+0.1,-23.5)\n",
    "plt.hist(centrals['Mr'],bins=50,label='centrals')\n",
    "plt.hist(satellites['Mr'],bins=50,label='satellites')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf09970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoPointCorrelationFunctionPeriodic(object):\n",
    "    \"\"\" 2-point (cross-)correlation functions in bins of separation. \n",
    "        Assumes complete, cubic periodic box throughout.\n",
    "    \"\"\"\n",
    "    #############################################################\n",
    "    def __init__(self,lgbin=1,rmin=1e-2,rmax=3e1,nbin=15,Lbox=300.0,proj=0,pimax=60.0):\n",
    "        \"\"\" Initialise the following:\n",
    "            -- lgbin      : use logarithmic (1) or linear (0) binning\n",
    "            -- rmin,rmax: min,max separations in r (or rp)\n",
    "            -- nbin      : number of bins in r (or rp).\n",
    "            -- Lbox     : Box size in same units as rmin,rmax,pimax.\n",
    "            -- proj       : if 1, calculate projected correlation function wp(rp), else xi(r)\n",
    "            -- pimax    : max separation in pi (bins in pi will be rp-dependent)\n",
    "             \n",
    "            Methods: \n",
    "            pair_counts,DD_only,RR_theory,twoPCF\n",
    "            \"\"\"\n",
    "        self.lgbin = lgbin\n",
    "        self.rmin = rmin\n",
    "        self.rmax = rmax\n",
    "        self.nbin = nbin\n",
    "        self.Lbox = Lbox\n",
    "        self.proj = proj\n",
    "        self.pimax = pimax\n",
    "\n",
    "        self.TINY = 1e-15\n",
    "        self.N_SPLIT = 8000 # max number of objects that can be handled on 1 cpu\n",
    "\n",
    "        print_string = \"Initialising 2pcf calculator for periodic boxes\\n\"\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "        if self.proj:\n",
    "            print(\"... projected 2pcf calculated\")\n",
    "            if self.lgbin==1:\n",
    "                self.rpbin = np.logspace(np.log10(self.rmin),np.log10(self.rmax),self.nbin+1)\n",
    "                self.rpmid = np.sqrt(self.rpbin[1:]*self.rpbin[:-1])\n",
    "            else:\n",
    "                self.rpbin = np.linspace(self.rmin,self.rmax,self.nbin+1)\n",
    "                self.rpmid = 0.5*(self.rpbin[1:]+self.rpbin[:-1])\n",
    "            self.NR = 50\n",
    "            self.NR_INT = self.NR*3 # seems converged at NR=50,NR_INT=50*3 or dlnr=0.13,dlnr_int=0.044\n",
    "            self.RMIN = self.rmin\n",
    "            self.RMAX = 0.5*self.Lbox # NOTE THIS\n",
    "            self.rbin = np.logspace(np.log10(self.RMIN),np.log10(self.RMAX),self.NR+1)\n",
    "            self.rmid = np.sqrt(self.rbin[1:]*self.rbin[:-1])\n",
    "            self.rbin_int = np.logspace(np.log10(self.RMIN),np.log10(self.RMAX),self.NR_INT+1)\n",
    "            self.rmid_int = np.sqrt(self.rbin_int[1:]*self.rbin_int[:-1])\n",
    "            self.dlnr_int = np.log(self.rmid_int[1]/self.rmid_int[0])\n",
    "        else:\n",
    "            print(\"... monopole 2pcf calculated\")\n",
    "            if self.lgbin==1:\n",
    "                self.rbin = np.logspace(np.log10(self.rmin),np.log10(self.rmax),self.nbin+1)\n",
    "                self.rmid = np.sqrt(self.rbin[1:]*self.rbin[:-1])\n",
    "            else:\n",
    "                self.rbin = np.linspace(self.rmin,self.rmax,self.nbin+1)\n",
    "                self.rmid = 0.5*(self.rbin[1:]+self.rbin[:-1])\n",
    "\n",
    "        print_string = \"... initialisation complete\\n\"\n",
    "        print_string += \"--------------------------------\"\n",
    "        print(print_string)\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    def pair_counts(self,pos_1,pos_2):\n",
    "        \"\"\" Unnormalised binned pair counts \n",
    "            between two data sets (can be the same data set).\n",
    "            pos_j should have shape (ndata_j,3) and\n",
    "            Returns vector of length self.nbin. \n",
    "        \"\"\"\n",
    "        tree_1 = syspat.cKDTree(pos_1,boxsize=self.Lbox)\n",
    "        tree_2 = syspat.cKDTree(pos_2,boxsize=self.Lbox)\n",
    "\n",
    "        cum_counts = tree_1.count_neighbors(tree_2,self.rbin,cumulative=True)\n",
    "        bin_counts = np.diff(cum_counts)\n",
    "\n",
    "        del tree_1,tree_2\n",
    "        gc.collect()\n",
    "        ###################\n",
    "\n",
    "        return bin_counts \n",
    "    #############################################################\n",
    "\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    def RR_theory(self):\n",
    "        print(\"... ... calculating RR from theory\")\n",
    "        # valid for rmax < Lbox/2, else see Deserno 04\n",
    "        return 4*np.pi/3*(self.rbin[1:]**3-self.rbin[:-1]**3)/self.Lbox**3\n",
    "    #############################################################\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    def twoPCF(self,pos_data,pos_data2=None):\n",
    "        \"\"\" Auto/cross-correlation of data points.\n",
    "            Assumes pos_data.shape() = (ndata,3).\n",
    "            Applies recursive binary split for large data sets.\n",
    "            Returns Peebles-Hauser estimator DD/RR - 1.\n",
    "        \"\"\"\n",
    "        if pos_data.shape[1] != 3:\n",
    "            raise TypeError(\"Incompatible data shape. Expected (ndata,3).\")\n",
    "\n",
    "        DD = self.DD_split(pos_data,pos_data2=pos_data2)\n",
    "\n",
    "        RR = self.RR_theory()\n",
    "        cf_r = DD/(RR + self.TINY) - 1.0    \n",
    "\n",
    "        if self.proj:\n",
    "            print(\"... ... projecting\")\n",
    "            cf = np.zeros(self.nbin,dtype=float)\n",
    "            cf_r_int = np.interp(self.rmid_int,self.rmid,cf_r)\n",
    "            for rp in range(self.nbin):\n",
    "                cond = (self.rmid_int > self.rpmid[rp]) & (self.rmid_int**2 < (self.rpmid[rp]**2 + self.pimax**2))\n",
    "                ind = np.where(cond)[0]\n",
    "                if ind.size:\n",
    "                    Drp = self.rmid_int[ind[0]] - self.rpmid[rp]\n",
    "                    add_this = np.sqrt(2*Drp/self.rpmid[rp])*cf_r_int[ind[0]]*self.rpmid[rp]\n",
    "                    cf[rp] = add_this + 2*np.trapz((self.rmid_int[cond]*cf_r_int[cond]\n",
    "                                                    /np.sqrt(self.rmid_int[cond]**2 - self.rpmid[rp]**2)),\n",
    "                                                   x=self.rmid_int[cond])\n",
    "        else:\n",
    "            cf = 1.0*cf_r\n",
    "\n",
    "        print(\"... ... done\")\n",
    "        \n",
    "        return cf\n",
    "    #############################################################\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    def DD_only(self,pos_data1,pos_data2=None):\n",
    "        \"\"\" DD (or D1D2) calculation.\n",
    "            Assumes pos_data1.shape() = (ndata,3).\n",
    "            If pos_data2 is not None, assumes pos_data2.shape() = (ndata2,3).\n",
    "            Returns DD or D1D2.\n",
    "        \"\"\"\n",
    "        ndata1 = pos_data1.shape[0]\n",
    "        if pos_data2 is None:\n",
    "            cf = 1.0*self.pair_counts(pos_data1,pos_data1)/ndata1/(ndata1-1)\n",
    "        else:\n",
    "            ndata2 = pos_data2.shape[0]\n",
    "            cf = 1.0*self.pair_counts(pos_data1,pos_data2)/ndata1/ndata2\n",
    "\n",
    "        return cf\n",
    "    #############################################################\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    def DD_split(self,pos_data,pos_data2=None):\n",
    "        \"\"\" DD calculation wrapper.\n",
    "            Assumes pos_data.shape() = (ndata,3).\n",
    "            If pos_data2 is not None, assumes pos_data2.shape() = (ndata2,3).\n",
    "            Returns DD (or D1D2), applying binary recursive split for large data sets.\n",
    "        \"\"\"\n",
    "        ndata = pos_data.shape[0]\n",
    "        ndata_by_2 = ndata//2\n",
    "        if ndata < self.N_SPLIT:\n",
    "            print_string = '... ... calculating '\n",
    "            print_string += \"DD\" if pos_data2 is None else \"D1D2\"\n",
    "            print(print_string)\n",
    "            cf = self.DD_only(pos_data,pos_data2=pos_data2)\n",
    "        else:\n",
    "            print(\"... ... binary split\")\n",
    "            if pos_data2 is None:\n",
    "                pd1s = pos_data[:ndata_by_2].copy()\n",
    "                ndata1s = pd1s.shape[0]\n",
    "                pd1spr = pos_data[ndata_by_2:].copy()\n",
    "                ndata1spr = pd1spr.shape[0]\n",
    "                D1D1 = self.DD_split(pd1s)\n",
    "                D1D1pr = self.DD_split(pd1s,pos_data2=pd1spr)\n",
    "                D1prD1pr = self.DD_split(pd1spr)\n",
    "                cf = ndata1s*(ndata1s-1)*D1D1 + 2*ndata1s*ndata1spr*D1D1pr + ndata1spr*(ndata1spr-1)*D1prD1pr\n",
    "                cf = 1.0*cf/ndata/(ndata-1)\n",
    "                del pd1s,pd1spr\n",
    "                gc.collect()\n",
    "            else:\n",
    "                ndata2 = pos_data2.shape[0]\n",
    "                ndata2_by_2 = ndata//2\n",
    "                pd1s = pos_data[:ndata_by_2].copy()\n",
    "                ndata1s = pd1s.shape[0]\n",
    "                pd1spr = pos_data[ndata_by_2:].copy()\n",
    "                ndata1spr = pd1spr.shape[0]\n",
    "                pd2s = pos_data2[:ndata2_by_2].copy()\n",
    "                ndata2s = pd2s.shape[0]\n",
    "                pd2spr = pos_data2[ndata2_by_2:].copy()\n",
    "                ndata2spr = pd2spr.shape[0]\n",
    "                D1D2 = self.DD_split(pd1s,pos_data2=pd2s)\n",
    "                D1D2pr = self.DD_split(pd1s,pos_data2=pd2spr)\n",
    "                D1prD2 = self.DD_split(pd1spr,pos_data2=pd2s)\n",
    "                D1prD2pr = self.DD_split(pd1spr,pos_data2=pd2spr)\n",
    "                cf = ndata1s*ndata2s*D1D2 + ndata1s*ndata2spr*D1D2pr \n",
    "                cf = cf + ndata1spr*ndata2s*D1prD2 + ndata1spr*ndata2spr*D1prD2pr\n",
    "                cf = 1.0*cf/ndata/ndata2\n",
    "                del pd1s,pd1spr,pd2s,pd2spr\n",
    "                gc.collect()\n",
    "\n",
    "        return cf\n",
    "    #############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcf_real = TwoPointCorrelationFunctionPeriodic(rmin=0.01,rmax=60.,nbin=20,Lbox=mm.Lbox,proj=0)\n",
    "tpcf = TwoPointCorrelationFunctionPeriodic(rmin=0.1,rmax=40.,nbin=20,Lbox=mm.Lbox,proj=1,pimax=40.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpos = np.array([centrals['x'],centrals['y'],centrals['z']]).T\n",
    "spos = np.array([satellites['x'],satellites['y'],satellites['z']]).T\n",
    "gpos = np.vstack((cpos,spos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fabd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('Centrals auto')\n",
    "# xir_cen = tpcf_real.twoPCF(cpos,cpos)\n",
    "# print('Satellites auto')\n",
    "# xir_sat = tpcf_real.twoPCF(spos,spos)\n",
    "# print('All auto')\n",
    "# xir_gal = tpcf_real.twoPCF(gpos,gpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"$r \\\\, (h^{{-1}}{{\\\\rm Mpc}})$\")\n",
    "# plt.ylabel(\"$\\\\xi(r)$\")\n",
    "# plt.plot(tpcf_real.rmid,xir_cen,'b-',label='centrals')\n",
    "# plt.plot(tpcf_real.rmid,xir_sat,'r-',label='satellites')\n",
    "# plt.plot(tpcf_real.rmid,xir_gal,'k-',label='all')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zehavi = np.loadtxt('data/zehavi_data_dex_separated.txt').T\n",
    "# z11_rp = zehavi[0]\n",
    "# z11_wp_20p5 = zehavi[7]\n",
    "# z11_errwp_20p5 = zehavi[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd60a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Centrals auto')\n",
    "wp_cen = tpcf.twoPCF(cpos,cpos)\n",
    "print('Satellites auto')\n",
    "wp_sat = tpcf.twoPCF(spos,spos)\n",
    "print('All auto')\n",
    "wp_gal = tpcf.twoPCF(gpos,gpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"$r_{{\\\\rm p}} \\\\, (h^{{-1}}{{\\\\rm Mpc}})$\")\n",
    "plt.ylabel(\"$w_{{\\\\rm p}}(r_{{\\\\rm p}}) \\\\, (h^{{-1}}{{\\\\rm Mpc}})$\")\n",
    "plt.plot(tpcf.rpmid,wp_cen,'b-',label='centrals')\n",
    "# plt.plot(tpcf.rpmid,wp_sat,'g-',label='satellites')\n",
    "plt.plot(tpcf.rpmid,wp_gal,'k-',label='cen + sat')\n",
    "# plt.errorbar(z11_rp,z11_wp_20p5,yerr=z11_errwp_20p5,ls='none',\n",
    "#              c='crimson',capsize=5,marker='o',label='Zehavi+11')\n",
    "plt.legend()\n",
    "# plt.savefig('fig-compareZ11wp-20p5.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf519478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22753bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
